{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyreadstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. PTR dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge all the PTR datasets from different years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the PTR datasets from 2018 to 2023\n",
    "df2018, meta2018 = pyreadstat.read_sas7bdat('/Users/liuyiqing/Desktop/data/ptr_hr_2018_ExtractedEXE/ptr_hr_20180101_20181231_pub.sas7bdat')\n",
    "df2019, meta2019 = pyreadstat.read_sas7bdat('/Users/liuyiqing/Desktop/data/ptr_hr_2018_ExtractedEXE/ptr_hr_20190101_20191231_pub.sas7bdat')\n",
    "df2020, meta2020 = pyreadstat.read_sas7bdat('/Users/liuyiqing/Desktop/data/ptr_hr_2018_ExtractedEXE/ptr_hr_20200101_20201231_pub.sas7bdat')\n",
    "df2021, meta2021 = pyreadstat.read_sas7bdat('/Users/liuyiqing/Desktop/data/ptr_hr_2018_ExtractedEXE/ptr_hr_20210101_20211231_pub.sas7bdat')\n",
    "df2022, meta2022 = pyreadstat.read_sas7bdat('/Users/liuyiqing/Desktop/data/ptr_hr_2018_ExtractedEXE/ptr_hr_20220101_20221231_pub.sas7bdat')\n",
    "df2023, meta2023 = pyreadstat.read_sas7bdat('/Users/liuyiqing/Desktop/data/ptr_hr_2018_ExtractedEXE/ptr_hr_20230101_20231231_pub.sas7bdat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## concate all the datasets to form a PTR dataframe, called PTR\n",
    "PTR = pd.concat([df2018, df2019, df2020, df2021, df2022, df2023], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## As the datasets are too huge, we only pick two years as example to run in local environment to check data and help with primary analysis\n",
    "PTR = pd.concat([df2022, df2023], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PTR_XMATCH_RESULT_ID'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "## delete the empty columns with NaNs\n",
    "all_na_columns = PTR.columns[PTR.isna().all()]\n",
    "\n",
    "print(all_na_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTR_OFFER_ACPT\n",
      "     2262792\n",
      "N    1159491\n",
      "Z     271181\n",
      "B      20333\n",
      "Y       9183\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## pick out our response variable, that is the PTR_OFFER_ACPT, which shows a heart is accepted or not.\n",
    "unique_values_count = PTR['PTR_OFFER_ACPT'].value_counts()\n",
    "print(unique_values_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. SAF dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyreadstat\n",
    "\n",
    "# read datasets\n",
    "df_tx_HR, meta_tx_HR = pyreadstat.read_sas7bdat('/Users/liuyiqing/Desktop/data/pubsaf2403/TX_HR.sas7bdat')\n",
    "df_immuno, meta_immuno = pyreadstat.read_sas7bdat('/Users/liuyiqing/Desktop/data/pubsaf2403/IMMUNO.sas7bdat')\n",
    "df_rec, meta_rec = pyreadstat.read_sas7bdat('/Users/liuyiqing/Desktop/data/pubsaf2403/REC_HISTO.sas7bdat')\n",
    "df_rec_x, meta_rec_x = pyreadstat.read_sas7bdat('/Users/liuyiqing/Desktop/data/pubsaf2403/REC_HISTO_XMAT.sas7bdat')\n",
    "df_deceased, meta_deceased = pyreadstat.read_sas7bdat('/Users/liuyiqing/Desktop/data/pubsaf2403/donor_deceased.sas7bdat')\n",
    "df_disposition, meta_disposition = pyreadstat.read_sas7bdat('/Users/liuyiqing/Desktop/data/pubsaf2403/donor_disposition.sas7bdat')\n",
    "df_cand, meta_cand = pyreadstat.read_sas7bdat('/Users/liuyiqing/Desktop/data/pubsaf2403/cand_thor.sas7bdat')\n",
    "df_hist, meta_hist = pyreadstat.read_sas7bdat('/Users/liuyiqing/Desktop/data/pubsaf2403/stathist_thor.sas7bdat')\n",
    "df_statjusta, meta_statjusta = pyreadstat.read_sas7bdat('/Users/liuyiqing/Desktop/data/pubsaf2403/statjust_hr1a.sas7bdat')\n",
    "df_statjustb, meta_statjustb = pyreadstat.read_sas7bdat('/Users/liuyiqing/Desktop/data/pubsaf2403/statjust_hr1b.sas7bdat')\n",
    "df_txf_HR, meta_txf_HR = pyreadstat.read_sas7bdat('/Users/liuyiqing/Desktop/data/pubsaf2403/txf_hr.sas7bdat')\n",
    "df_fol_immu, meta_fol_immu = pyreadstat.read_sas7bdat('/Users/liuyiqing/Desktop/data/pubsaf2403/fol_immuno.sas7bdat')\n",
    "df_malig, meta_malig = pyreadstat.read_sas7bdat('/Users/liuyiqing/Desktop/data/pubsaf2403/malig.sas7bdat')\n",
    "df_treat, meta_treat = pyreadstat.read_sas7bdat('/Users/liuyiqing/Desktop/data/pubsaf2403/treatment.sas7bdat')\n",
    "\n",
    "# filter columns in different datasets\n",
    "columns_to_include = {\n",
    "    'df_tx_HR': [\n",
    "        'CAN_ABO', 'CAN_AGE_AT_LISTING', 'CAN_AGE_IN_MONTHS_AT_LISTING', 'CAN_CARDIAC_OUTPUT', 'CAN_CITIZENSHIP', 'CAN_DGN', \n",
    "        'CAN_EDUCATION', 'CAN_ETHNICITY_SRTR', 'CAN_GENDER', 'CAN_HGT_CM', 'CAN_INIT_ACT_STAT_CD', 'CAN_INIT_STAT', \n",
    "        'CAN_LAST_STAT', 'CAN_LISTING_DT', 'CAN_WGT_KG', 'DON_AGE', 'DON_AGE_IN_MONTHS', 'DON_ANTI_HCV', 'DON_CAD_DON_COD', \n",
    "        'DON_CARDIAC_ARREST_AFTER_DEATH', 'DON_CITIZENSHIP', 'DON_CONT_CIGARETTE', 'DON_CONT_COCAINE', 'DON_CONT_IV_DRUG', \n",
    "        'DON_CREAT', 'DON_DOBUTAMINE', 'DON_DOPAMINE', 'DON_ETHNICITY_SRTR', 'DON_GENDER', 'DON_HGT_CM', 'DON_HIST_CANCER', \n",
    "        'DON_HIST_COCAINE', 'DON_HIST_DIAB', 'DON_HIST_HYPERTEN', 'DON_HIST_IV_DRUG', 'DON_HIST_OTHER_DRUG', 'DON_INOTROP_AGENT_GE3', \n",
    "        'DON_INOTROP_SUPPORT', 'DON_NON_HR_BEAT', 'DON_RACE_SRTR', 'DON_RECOV_DT', 'DON_WARM_ISCH_TM_MINS', 'DON_WGT_KG', 'DONOR_ID', \n",
    "        'REC_CARDIAC_OUTPUT', 'REC_CREAT', 'PX_ID', 'TRR_ID', 'TX_ID', 'REC_HISTO_TX_ID'\n",
    "    ],\n",
    "    'df_cand': [\n",
    "        'CAN_ABO', 'CAN_ACPT_ABO_INCOMP', 'CAN_AGE_AT_LISTING', 'CAN_AGE_IN_MONTHS_AT_LISTING', 'CAN_CARDIAC_OUTPUT', 'CAN_CITIZENSHIP', \n",
    "        'CAN_DGN', 'CAN_EDUCATION', 'CAN_ETHNICITY_SRTR', 'CAN_GENDER', 'CAN_HGT_CM', 'CAN_INIT_ACT_STAT_CD', 'CAN_INIT_STAT', \n",
    "        'CAN_LAST_STAT', 'CAN_LISTING_CTR_CD', 'CAN_LISTING_DT', 'CAN_PCW_MEAN', 'CAN_PERM_STATE', 'CAN_PRIMARY_PAY', 'CAN_SECONDARY_PAY', \n",
    "        'CAN_WGT_KG', 'DONOR_ID', 'PX_ID'\n",
    "    ],\n",
    "    'df_hist': [\n",
    "        'CAN_INIT_ACT_STAT_CD', 'CAN_INIT_STAT', 'CAN_LAST_STAT', 'CAN_LISTING_DT', 'PX_ID'\n",
    "    ],\n",
    "    'df_statjustb': [\n",
    "        'CAN_LISTING_CTR_CD', 'PX_ID'\n",
    "    ],\n",
    "    'df_statjusta': [\n",
    "        'CAN_LISTING_CTR_CD', 'CANHX_INTRP_NOREPINE', 'PX_ID'\n",
    "    ],\n",
    "    'df_deceased': [\n",
    "        'DON_ABNORM_LVH', 'DON_ABNORM_VALVES', 'DON_AGE', 'DON_AGE_IN_MONTHS', 'DON_ANTI_HBC', 'DON_ANTI_HCV', 'DON_ANTI_HIV', 'DON_ANTI_HTLV', \n",
    "        'DON_BUN', 'DON_CAD_DON_COD', 'DON_CANCER_OTHER_OSTXT', 'DON_CARDIAC_ARREST_AFTER_DEATH', 'DON_CHEST_XRAY', 'DON_CITIZENSHIP', 'DON_CLAMP_DT', \n",
    "        'DON_CLAMP_TM', 'DON_CLAMP_TM_ZONE', 'DON_CO_FINAL', 'DON_CO_INIT', 'DON_COD_DON_STROKE', 'DON_CONT_ALCOHOL', 'DON_CONT_CIGARETTE', \n",
    "        'DON_CONT_COCAINE', 'DON_CONT_IV_DRUG', 'DON_CORONARY_ANGIO', 'DON_DOBUTAMINE', 'DON_DOPAMINE', 'DON_EJECT_FRACT', 'DON_EJECT_FRACT_METH', \n",
    "        'DON_ETHNICITY_SRTR', 'DON_FEEDBACK_DONE', 'DON_GENDER', 'DON_HBV_NAT', 'DON_HBV_SURF_ANTIGEN', 'DON_HCV_NAT', 'DON_HCV_STAT', 'DON_HGT_CM', \n",
    "        'DON_HIST_CANCER', 'DON_HIST_PREV_MI', 'DON_HOME_STATE', 'DON_INFECT_BLOOD', 'DON_INFECT_BLOOD_CONFIRM', 'DON_INFECT_LU', 'DON_INFECT_LU_CONFIRM', \n",
    "        'DON_INFECT_OTHER', 'DON_INFECT_OTHER_CONFIRM', 'DON_INFECT_URINE', 'DON_INFECT_URINE_CONFIRM', 'DON_LEGALLY_BRAIN_DEAD', 'DON_MEET_CDC_HIGH_RISK', \n",
    "        'DON_NON_HR_BEAT', 'DON_RECOV_DT', 'DON_TROPONIN_I', 'DON_TROPONIN_T', 'DON_WALL_ABNORM_SEG', 'DON_WARM_ISCH_TM_MINS', 'DON_WGT_KG', 'DONOR_ID'\n",
    "    ],\n",
    "    'df_disposition': [\n",
    "        'DON_RECOV_DT', 'DONOR_ID', 'PX_ID'\n",
    "    ],\n",
    "    'df_rec': [\n",
    "        'REC_HLA_INTERPRET_I', 'REC_HLA_TYP_DONE', 'REC_HISTO_TX_ID'\n",
    "    ],\n",
    "    'df_rec_x': [\n",
    "        'REC_HISTO_TX_ID'\n",
    "    ],\n",
    "    'df_immuno': [\n",
    "        'TRR_ID'\n",
    "    ],\n",
    "    'df_txf_HR': [\n",
    "        'PX_ID', 'TRR_ID', 'TX_ID'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tx_HR = df_tx_HR[columns_to_include['df_tx_HR']]\n",
    "df_immuno = df_immuno[columns_to_include['df_immuno']]\n",
    "df_rec = df_rec[columns_to_include['df_rec']]\n",
    "df_rec_x = df_rec_x[columns_to_include['df_rec_x']]\n",
    "df_deceased = df_deceased[columns_to_include['df_deceased']]\n",
    "df_disposition = df_disposition[columns_to_include['df_disposition']]\n",
    "df_cand = df_cand[columns_to_include['df_cand']]\n",
    "df_hist = df_hist[columns_to_include['df_hist']]\n",
    "df_statjusta = df_statjusta[columns_to_include['df_statjusta']]\n",
    "df_statjustb = df_statjustb[columns_to_include['df_statjustb']]\n",
    "df_txf_HR = df_txf_HR[columns_to_include['df_txf_HR']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: TRANSPLANT INFORMATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Pick Donors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## only keep donors who have TRANSPLANT INFORMATION for heart in PTR dataframe\n",
    "donor_ids_hr = df_tx_HR['DONOR_ID'].unique()\n",
    "PTR = PTR[PTR['DONOR_ID'].isin(donor_ids_hr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select 10 donors as Sample\n",
    "unique_donor_ids = PTR['DONOR_ID'].unique()\n",
    "selected_donor_ids = unique_donor_ids[:100]\n",
    "\n",
    "## Re-define the PTR as a filtered one\n",
    "PTR = PTR[PTR['DONOR_ID'].isin(selected_donor_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Merge TRANSPLANT INFORMATION for Deceased HR Donors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pick out the selected first 10 donors\n",
    "HR_donor = df_tx_HR[df_tx_HR['DONOR_ID'].isin(selected_donor_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 50)\n"
     ]
    }
   ],
   "source": [
    "print(HR_donor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use keys, TRR_ID, TX_ID, to merge the datasets\n",
    "D_HR_immu = pd.merge(HR_donor, df_immuno, on='TRR_ID', how='left', suffixes=('_dec_tx', '_immu'))\n",
    "D_HR_rec = pd.merge(D_HR_immu, df_rec, left_on='TX_ID', right_on='REC_HISTO_TX_ID', how='left', suffixes=('_dec_tx_immu', '_rec'))\n",
    "D_HR_recx = pd.merge(D_HR_rec, df_rec_x, left_on='TX_ID', right_on='REC_HISTO_TX_ID', how='left', suffixes=('_dec_tx_immu_rec', '_recx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['REC_HLA_INTERPRET_I', 'REC_HISTO_TX_ID'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "## Check the empty columns\n",
    "all_na_columns = D_HR_recx.columns[D_HR_recx.isna().all()]\n",
    "print(all_na_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: DONOR INFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use keys DONOR_ID, to merge the datasets\n",
    "D_HR_dec = pd.merge(D_HR_recx, df_deceased, on='DONOR_ID', how='left', suffixes=('_dec', '_tx'))\n",
    "D_HR = pd.merge(D_HR_dec, df_disposition, on='DONOR_ID', how='left', suffixes=('_d', '_t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['REC_HLA_INTERPRET_I', 'REC_HISTO_TX_ID', 'DON_CLAMP_TM',\n",
      "       'DON_CLAMP_TM_ZONE', 'DON_CO_FINAL'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "## Check the empty columns\n",
    "all_na_columns = D_HR.columns[D_HR.isna().all()]\n",
    "print(all_na_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: CANDIDATE INFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use key PX_ID, to merge the datasets\n",
    "D_HR_cand = pd.merge(D_HR, df_cand, left_on='PX_ID_d', right_on='PX_ID', how='left', suffixes=('_recx2', '_cand'))\n",
    "D_HR_hist = pd.merge(D_HR_cand, df_hist, on='PX_ID', how='left', suffixes=('_cand2', '_hist'))\n",
    "D_HR_statjusta = pd.merge(D_HR_hist, df_statjusta, on='PX_ID', how='left', suffixes=('_cand_hist', '_justa'))\n",
    "D_HR_statjustb = pd.merge(D_HR_statjusta, df_statjustb, on='PX_ID', how='left', suffixes=('_cand_hist', '_justb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['REC_HLA_INTERPRET_I', 'REC_HISTO_TX_ID', 'DON_CLAMP_TM',\n",
      "       'DON_CLAMP_TM_ZONE', 'DON_CO_FINAL', 'CAN_SECONDARY_PAY',\n",
      "       'CANHX_INTRP_NOREPINE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "## Check and delete the empty columns\n",
    "all_na_columns = D_HR_statjustb.columns[D_HR_statjustb.isna().all()]\n",
    "print(all_na_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 4: TRANSPLANT FOLLOW-UP INFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use keys TX_ID, TRR_FOL_ID and MALIG_ID, to merge the datasets\n",
    "D_HR_txf = pd.merge(D_HR_statjustb, df_txf_HR, on='TX_ID', how='left', suffixes=('_cand3', '_txf'))\n",
    "# D_HR_fol_immu = pd.merge(D_HR_txf, df_fol_immu, on='TRR_FOL_ID', how='left', suffixes=('_cand_txf', '_fol_immu'))\n",
    "# D_HR_malig = pd.merge(D_HR_fol_immu, df_malig, on='TRR_FOL_ID', how='left', suffixes=('_cand_txf_fol', '_malig'))\n",
    "# D_HR_treat = pd.merge(D_HR_malig, df_treat, on='MALIG_ID', how='left', suffixes=('_malig2', '_treat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['REC_HLA_INTERPRET_I', 'REC_HISTO_TX_ID', 'DON_CLAMP_TM',\n",
      "       'DON_CLAMP_TM_ZONE', 'DON_CO_FINAL', 'CAN_SECONDARY_PAY',\n",
      "       'CANHX_INTRP_NOREPINE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "## Check and delete the empty columns\n",
    "all_na_columns = D_HR_txf.columns[D_HR_txf.isna().all()]\n",
    "print(all_na_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Check and delete the empty columns\n",
    "# all_na_columns = D_HR_treat.columns[D_HR_treat.isna().all()]\n",
    "# D_HR_treat = D_HR_treat.dropna(axis=1, how='all')\n",
    "# print(all_na_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Merge PTR and SAF datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the Deceased Heart Donor information as DHR_INFO, use keys DONOR_ID to merge the datasets\n",
    "DHR_INFO = pd.merge(D_HR_txf, PTR, left_on='DONOR_ID_recx2', right_on='DONOR_ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTR_OFFER_ACPT\n",
      "     4942894\n",
      "Z     878233\n",
      "N     428261\n",
      "B      37280\n",
      "Y      25512\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "unique_values_count = DHR_INFO['PTR_OFFER_ACPT'].value_counts()\n",
    "print(unique_values_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONOR_ID\n",
      "642567.0    1461600\n",
      "646241.0     762048\n",
      "646377.0     691200\n",
      "630538.0     359100\n",
      "643720.0     176400\n",
      "             ...   \n",
      "631679.0       7392\n",
      "646010.0       4956\n",
      "640460.0       4200\n",
      "633455.0       2560\n",
      "642100.0       1764\n",
      "Name: count, Length: 100, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "unique_values_count = DHR_INFO['DONOR_ID'].value_counts()\n",
    "print(unique_values_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6312180, 175)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DHR_INFO.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "DHR_INFO.to_csv('DHR_INFO_100.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
